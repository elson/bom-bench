# Purpose
- Provide concise, actionable guidance to AI coding agents working on this repository.

# Big picture
- See `./README.md` for context.

# Project status
- This project is in early, pre-alpha stage. 
- Breaking changes are completely acceptable, there are no real users yet. 
- Do not add shims, aliases, switches or similar code to maintain backward compatibility

# Key files and folders
- `./src/bom_bench/` - main package with modular plugin architecture
  - `cli.py` - CLI orchestration and entry points
  - `plugins/` - Pluggy-based plugin system and hook specifications
  - `package_managers/` - package manager plugins (e.g., uv.py)
  - `sca_tools/` - SCA tool plugins (cdxgen.py, syft.py)
  - `benchmarking/` - benchmark runner, comparison, and storage
  - `data/` - data source loading
  - `models/` - data models
- `./data/` - data sources (packse, etc.) - fetched automatically if needed
- `./output/scenarios/{pm}/{scenario}/` - generated projects with `assets/` subdirectory

# Available tools
- `uv` - Python package manager and build tool
- `packse` - Python package and CLI tool. The script uses the Python API (`packse.fetch`, `packse.inspect`) to fetch and load scenarios programmatically.
- `cdxgen` - CycloneDX SBOM generator (SCA tool plugin)
- `syft` - Anchore Syft SBOM generator (SCA tool plugin)

# Developer workflows
- Use `uv` to manage environments and runs where possible.
- Create or manage a venv with `uv venv`.
- Declare any non-stdlib dependencies in the `pyproject.toml` file
- Run commands inside the `uv` environment using `uv run`, for example:

```bash
# Generate manifests, lock files, and expected SBOMs (requires packse server)
uv run bom-bench setup

# Run SCA tool benchmarks against generated projects
uv run bom-bench benchmark --tools cdxgen,syft

# List available SCA tools
uv run bom-bench list-tools --check
```

# Testing
- Use test driven development (TDD). Write the test first. Watch it fail. Write minimal code to pass.
- Test your work by running `uv run bom-bench setup` and checking the output
- Run the test suite: `uv run pytest tests/ -v`
- To test setup/benchmark, ensure packse server is running at http://127.0.0.1:3141 first.

# Project-specific conventions
- Target interpreter: Python 3.12 — keep syntax and stdlib usage compatible.
- Dependencies: Uses `packse`, `pluggy`, `packageurl-python` packages (declared in `pyproject.toml`).
- Output structure (`output/scenarios/{pm}/{scenario}/`):
  - `expected.cdx.json` - ground truth CycloneDX SBOM (pure format, only for satisfiable scenarios)
  - `meta.json` - scenario metadata with `satisfiable` flag and `package_manager_result` (exit_code, stdout, stderr)
  - `assets/pyproject.toml` - generated manifest
  - `assets/uv.lock` - lock file
- Benchmark outputs (`output/benchmarks/{tool}/{pm}/{scenario}/`):
  - `actual.cdx.json` - SBOM generated by SCA tool
  - `result.json` - comparison metrics
- Filtering rules:
  - Only process scenarios with `resolver_options.universal: true`
  - Exclude scenarios with "example" in the name
- Dependency naming: use full scenario-prefixed package names without hash suffixes from `root.requires[].requirement` field (obtained via `packse.inspect.variables_for_templates(..., no_hash=True)`).

# Patterns & examples
- Auto-fetch: Check if `./scenarios/` exists; if not, call `packse.fetch.fetch(dest=scenarios_dir)` to download scenarios.
- Discovery: Use `packse.inspect.find_scenario_files(scenarios_dir)` to discover scenario files, then `packse.inspect.variables_for_templates(scenario_files, no_hash=True)` to load scenario data.
- Iteration: Iterate through `template_vars['scenarios']` array, check `resolver_options.universal`, use `name` field for output directory.
- Dependencies: Extract from `root.requires[].requirement` (e.g., "wrong-backtracking-basic-a==1.0.0").

# Integration points
- `packse` Python API: scenarios are fetched using `packse.fetch.fetch()` and loaded using `packse.inspect` module.
- `uv`: prefer `uv` tooling for venvs, installs, and running scripts; it centralizes environment management.

# What to avoid
- Do not manually read TOML files from `./scenarios/`; always use the packse API (`packse.inspect.variables_for_templates()`).
- Do not process scenarios where `resolver_options.universal != true`.
- Keep external dependencies minimal; currently only `packse` is required.

# If you change behavior
- Update `README.md` to reflect new flags, outputs, runtime requirements and additional usage instructions.

## bom-bench Module Architecture

### Core Modules

**cli.py** - CLI orchestration and entry point
- Argument parsing and validation
- Multi-PM orchestration
- Progress reporting

**config.py** - Configuration constants
- Default paths and settings
- Project metadata (name, version)

### Plugin System (`plugins/`)

**hookspecs.py** - Pluggy hook specifications for PM and SCA tools
**__init__.py** - Plugin manager, DEFAULT_PLUGINS tuple, initialization

### Package Managers (`package_managers/`)

Plugin-based architecture using Pluggy hooks:
- **uv.py** ✅ - UV package manager (includes packse scenario loading)

### SCA Tools (`sca_tools/`)

Plugin-based SCA tool integrations:
- **cdxgen.py** ✅ - CycloneDX generator
- **syft.py** ✅ - Anchore Syft

### Data Layer (`data/`)

**sources/packse.py** - Packse scenario loading (used by UV plugin)

### Generators (`generators/`)

**uv/** ✅ - UV manifest (pyproject.toml) generation
**sbom/** ✅ - CycloneDX SBOM generation

### Models (`models/`)

**scenario.py** - Scenario data models
**result.py** - Processing and lock results
**package_manager.py** - PM metadata and PMInfo
**sca.py** - SCA tool models, benchmark results, metrics

### Benchmarking (`benchmarking/`)

**runner.py** ✅ - Benchmark orchestration, scenario iteration
**comparison.py** ✅ - SBOM comparison, PURL extraction and normalization
**storage.py** ✅ - Result persistence (JSON, CSV)
**collectors.py** - Result collection and normalization
**reporters.py** - Benchmark report generation

For detailed extension guides, see CONTRIBUTING.md
